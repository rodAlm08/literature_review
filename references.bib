@misc{doshivelez2017rigorous,
      title={Towards A Rigorous Science of Interpretable Machine Learning}, 
      author={Finale Doshi-Velez and Been Kim},
      year={2017},
      eprint={1702.08608},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
},

@misc{xai-concept,
    key = {https://www.darpa.mil/ddm_gallery/xai-figure2-inline-graphic.png},
    note = {AI concept vs. XAI Concept}

},

@article{xai-ml,
  title={Current challenges and future opportunities for XAI in machine learning-based clinical decision support systems: a systematic review},
  author={Antoniadi, Anna Markella and Du, Yuhan and Guendouz, Yasmine and Wei, Lan and Mazo, Claudia and Becker, Brett A and Mooney, Catherine},
  journal={Applied Sciences},
  volume={11},
  number={11},
  pages={5088},
  year={2021},
  publisher={MDPI}
},

@article{transparency,
  author={Adadi, Amina and Berrada, Mohammed},
  journal={IEEE Access}, 
  title={Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)}, 
  year={2018},
  volume={6},
  number={},
  pages={52138-52160},
  doi={10.1109/ACCESS.2018.2870052}
},

@misc{gilpin2019explaining,
      title={Explaining Explanations: An Overview of Interpretability of Machine Learning}, 
      author={Leilani H. Gilpin and David Bau and Ben Z. Yuan and Ayesha Bajwa and Michael Specter and Lalana Kagal},
      year={2019},
      eprint={1806.00069},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
},

@article{analytical-review,
  author = {Angelov, P. and Soares, E. and Jiang, R. and Arnold, N. I. and Atkinson, P. M.},
  title = {Explainable artificial intelligence: an analytical review},
  journal = {WIREs Data Mining and Knowledge Discovery},
  year = {2021},
  volume = {11},
  issue = {5},
  doi = {10.1002/widm.1424}
}

@article{phillips2020four,
  title={Four principles of explainable artificial intelligence},
  author={Phillips, P Jonathon and Hahn, Carina A and Fontana, Peter C and Broniatowski, David A and Przybocki, Mark A},
  journal={Gaithersburg, Maryland},
  volume={18},
  year={2020}
}

@inproceedings{why-trust-you,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135â€“1144},
numpages = {10},
keywords = {interpretability, explaining machine learning, black box classifier, interpretable machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}
,
@misc{rudin,
    key = {https://scholar.google.com/citations?user=mezKJyoAAAAJ&hl=en},
    note = {Cynthia Rudin}

}
,
@misc{radin,
    key = {https://hdsr.mitpress.mit.edu/user/joanna-radin},
    note = {Joanna Radin}

},


@article{Rudin2019Why,
	author = {Rudin, Cynthia and Radin, Joanna},
	journal = {Harvard Data Science Review},
	number = {2},
	year = {2019},
	month = {nov 22},
	note = {https://hdsr.mitpress.mit.edu/pub/f9kuryi8},
	publisher = {},
	title = {Why {Are} {We} {Using} {Black} {Box} {Models} in {AI} {When} {We} {Don}\textquoteright{}t {Need} {To}? {A} {Lesson} {From} an {Explainable} {AI} {Competition}},
	volume = {1},
},
@misc{misc_adult_2,
  author       = {Becker,Barry and Kohavi,Ronny},
  title        = {{Adult}},
  year         = {1996},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: 
                   https://doi.org/10.24432/C5XW20}
},
@inproceedings{petkovic2018improving,
  title={Improving the explainability of Random Forest classifier--user centered approach},
  author={Petkovic, Dragutin and Altman, Russ and Wong, Mike and Vigil, Arthur},
  booktitle={Pacific symposium on biocomputing 2018: proceedings of the pacific symposium},
  pages={204--215},
  year={2018},
  organization={World Scientific}
}